{
    "cord_uid": "ff7dg890",
    "source_x": "PMC",
    "pmcid": "PMC1181873",
    "divid": "10",
    "text": "The most commonly used framework for epidemiological systems, is still the susceptible-infectious-recovered (SIR) class of models, in which the host population is categorized according to infection status as either susceptible, infectious, or recovered [16, 17] . Subsequent refinements of the model have incorporated an additional exposed (infected but not yet infectious) class (susceptible-exposed-infectious-recovered [SEIR] models) (see Protocol S1 for mathematical equations). One of the fundamental mathematical assumptions in such models is that the rate of leaving the exposed or infectious class is constant, irrespective of the period already spent in that class. While mathematically very convenient, this assumption gives rise to exponentially distributed latent and infectious periods, which is epidemiologically unrealistic for most infections [18] [19] [20] . A more sensible formulation would be to specify the probability of leaving a class as a function of the time spent within the class, such that initially the chance of leaving the class is small, but the probability increases as the mean infectious/latent period is reached. This would give rise to a more realistic distribution of latent and infectious periods, with a stronger central tendency. A convenient way to describe such distributions is to write an expression for the infectious class (neglecting the latent class for this example) as follows: ",
    "project": "cdlai_CORD-19",
    "denotations": [
        {
            "id": "S-scispacy-abbr_T1",
            "span": {
                "begin": 109,
                "end": 112
            },
            "obj": "Abbreviation"
        }
    ]
}